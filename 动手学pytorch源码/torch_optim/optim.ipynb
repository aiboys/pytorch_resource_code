{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": "\n# torch优化器的源码解读\n\n主要涉及到 `torch.optim`包下的`optimizer.py`的`optimizer` 基类\n\n参考[torch.optim.optimizer class](https://pytorch.org/docs/stable/optim.html?highlight\u003doptimizer#torch.optim.Optimizer) 以及 [分模块学习率赋值](https://blog.csdn.net/weixin_43593330/article/details/108491755)\n[weight和bias学习率](https://blog.csdn.net/qq_17464457/article/details/101846874)\n"
    },
    {
      "cell_type": "markdown",
      "source": "\n平时我们所用的优化器都是在torch.optim包下所定义的，比如SGD, Adam两个优化器.\n这两个优化器都是以torch.optim.optimizer.py包下的optimzer为基类，该类定义了如下的几个重要attri:\n\n* 1. self.__getstate__(), self.__setstate__() 参考 动手学python的说明文(目的是为了方便自定义打包)\n* 2. self.state_dict(), self.load_state_dict(): 和`nn.Moudle`类一致，得到优化器的state,便于打包和按照打包的优化器超参数\n    进行下一次的相同优化\n* 3. self.step(): 优化更新(利用梯度下降法更新公式)\n* 4. self.add_param_groups(): 打包权重和bias到优化器的\u0027params_group\u0027参数\n\n基于上述的优化器类，我们可以得到优化器的结构如下：\n\n```\noptim\n-- defaults:--\u003e dict{\u0027lr\u0027: , \u0027momentum\u0027: , \u0027weight_decay\u0027: , ...}\n-- state:这个一般不管\n-- param_groups: --\u003e list[{}, {}, {}] (如果是不分组，比如 优化器的参数为model.parameters()的迭代器，则\n                            全部的参数都是共享学习率和decay;  但是如果要分组，那么就按照每一个组\n                                为一个list的元素，每个下标数据为一个dict：\n                                \u0027params\u0027: {list} (权重和bias都分别为一个数据点)\n                                \u0027lr\u0027:\n                                \u0027weight_decay\u0027:\n                                ...)\n```\n\n\n因此在进行优化器参数赋值的时候，最关键的就是组织好\u0027param\u0027参数，其形式为:\n[{\u0027params\u0027: [Parameter]}, {\u0027params\u0027: [Parameter]}, {},...]\n\n```\n**注意**:\n\n1.优化器的`param`参数可以是tensor的迭代器,也可以是dict.\n2. If you need to move a model to GPU via .cuda(), please do so before constructing optimizers for it. Parameters of a model after .cuda() will be different objects with those before the call.\n    In general, you should make sure that optimized parameters live in consistent locations when optimizers are constructed and used.\n```\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "SGD (\nParameter Group 0\n    dampening: 0\n    lr: 0.1\n    momentum: 0\n    nesterov: False\n    weight_decay: 0\n)\n0\n1\n2\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "\n# 模型以及基本的最简单优化器搭建\n\nimport torch.optim as optim\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass CivilNet(nn.Module):\n    def __init__(self):\n        super(CivilNet, self).__init__()\n        self.conv1 \u003d nn.Conv2d(3, 6, 5)\n        self.pool \u003d nn.MaxPool2d(2, 2)\n        self.conv2 \u003d nn.Conv2d(6, 16, 5)\n        self.fc1 \u003d nn.Linear(16 * 22 * 22, 120)\n        self.fc2 \u003d nn.Linear(120, 84)\n        self.fc \u003d nn.Sequential(nn.Linear(84, 10),\n                                nn.ReLU(),\n                                nn.Linear(10,2))\n\n    def forward(self, x):\n        x \u003d self.pool(F.relu(self.conv1(x)))\n        x \u003d self.pool(F.relu(self.conv2(x)))\n        x \u003d x.view(-1, 16 * 22 * 22)\n        x \u003d F.relu(self.fc1(x))\n        x \u003d F.relu(self.fc2(x))\n        x \u003d self.fc(x)\n        return x\ndevice \u003d torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel \u003d CivilNet().to(device)\n\nopt \u003d optim.SGD(model.parameters(), lr\u003d0.1) \nprint(\n    opt\n)\n\ninput \u003d torch.randn((1,3,100,100))\ninput \u003d input.to(device)\n\nloss_fn \u003d nn.MSELoss()\n\nfor i in range(3):\n    opt.zero_grad()\n    output \u003d model(input)\n    label \u003d torch.empty(1, 2, dtype\u003dtorch.float).random_(5).to(device)\n    loss \u003d loss_fn(output, label)\n    loss.backward()\n    opt.step()\n    print(i)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% \n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n## 分模块进行学习率的赋值\n\n参考[官方文档说明](https://pytorch.org/docs/stable/optim.html?highlight\u003doptimizer#torch.optim.Optimizer)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "8\nSGD (\nParameter Group 0\n    dampening: 0\n    lr: 0.001\n    momentum: 0.9\n    nesterov: False\n    weight_decay: 0\n\nParameter Group 1\n    dampening: 0\n    lr: 0.0015\n    momentum: 0.9\n    nesterov: False\n    weight_decay: 0\n\nParameter Group 2\n    dampening: 0\n    lr: 0.002\n    momentum: 0.9\n    nesterov: False\n    weight_decay: 0\n)\n",
            "0\n1\n2\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "\nlr \u003d 1e-3\nconv1_params \u003d list(map(id, model.conv1.parameters()))\nconv2_params \u003d list(map(id, model.conv2.parameters()))\nbase_params \u003d filter(lambda p: id(p) not in conv1_params + conv2_params, model.parameters())\nbase_pa \u003d list(base_params)\nprint(len(base_pa))\nparams \u003d [{\u0027params\u0027: base_pa},\n          {\u0027params\u0027: list(model.conv1.parameters()), \u0027lr\u0027: lr * 1.5},\n          {\u0027params\u0027: list(model.conv2.parameters()), \u0027lr\u0027: lr * 2.0}]\n\nopt2 \u003d torch.optim.SGD(params, lr\u003dlr, momentum\u003d0.9)\nprint(opt2)\ninput \u003d torch.randn((1,3,100,100))\ninput \u003d input.to(device)\n\nloss_fn \u003d nn.MSELoss()\n\nfor i in range(3):\n    opt.zero_grad()\n    output \u003d model(input)\n    label \u003d torch.empty(1, 2, dtype\u003dtorch.float).random_(5).to(device)\n    loss \u003d loss_fn(output, label)\n    loss.backward()\n    opt.step()\n    print(i)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n## 分weight和bias的学习率\n\n合理利用nn.Moudle的parameters()方法得到不同组的参数,然后设置学习率\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    eps: 1e-08\n    lr: 0.001\n    weight_decay: 0\n\nParameter Group 1\n    amsgrad: False\n    betas: (0.9, 0.999)\n    eps: 1e-08\n    lr: 0.0001\n    weight_decay: 0\n\nParameter Group 2\n    amsgrad: False\n    betas: (0.9, 0.999)\n    eps: 1e-08\n    lr: 0.001\n    weight_decay: 0\n\nParameter Group 3\n    amsgrad: False\n    betas: (0.9, 0.999)\n    eps: 1e-08\n    lr: 0.0001\n    weight_decay: 0\n\nParameter Group 4\n    amsgrad: False\n    betas: (0.9, 0.999)\n    eps: 1e-08\n    lr: 0.001\n    weight_decay: 0\n\nParameter Group 5\n    amsgrad: False\n    betas: (0.9, 0.999)\n    eps: 1e-08\n    lr: 0.0001\n    weight_decay: 0\n\nParameter Group 6\n    amsgrad: False\n    betas: (0.9, 0.999)\n    eps: 1e-08\n    lr: 0.0001\n    weight_decay: 0\n\nParameter Group 7\n    amsgrad: False\n    betas: (0.9, 0.999)\n    eps: 1e-08\n    lr: 0.0002\n    weight_decay: 0\n)\n0\n1\n2\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "lr \u003d 0.001\nparams \u003d []\nfc_params \u003d dict(model.fc.named_parameters())\nfor key, value in fc_params.items():\n        if \u0027bias\u0027 not in key:\n            params +\u003d [{\u0027params\u0027: [value], \u0027lr\u0027: lr}]\n        else:\n            params +\u003d [{\u0027params\u0027: [value], \u0027lr\u0027: lr * 0.1}]\nconv4_param \u003d dict(model.conv1.named_parameters())\nfor key, value in conv4_param.items():\n        if \u0027bias\u0027 not in key:\n            params +\u003d [{\u0027params\u0027: [value], \u0027lr\u0027: lr}]\n        else:\n            params +\u003d [{\u0027params\u0027: [value], \u0027lr\u0027: lr * 0.1}]\n\nparams +\u003d [{\u0027params\u0027: model.conv2.parameters(), \u0027lr\u0027: lr * 0.1}]\nconv1_id \u003d list(map(id, model.conv1.parameters()))\nconv2_id \u003d list(map(id, model.conv2.parameters()))\nfc_id \u003d list(map(id,model.fc.parameters()))\nbase_param \u003d list(filter(lambda p: id(p) not in conv1_id+ conv2_id+ fc_id, model.parameters()))\n\nparams +\u003d [{\u0027params\u0027: base_param, \u0027lr\u0027: lr*0.2}]\n\nopt\u003d optim.Adam(params)\n\nprint(opt)\ninput \u003d torch.randn((1,3,100,100))\ninput \u003d input.to(device)\n\nloss_fn \u003d nn.MSELoss()\n\nfor i in range(3):\n    opt.zero_grad()\n    output \u003d model(input)\n    label \u003d torch.empty(1, 2, dtype\u003dtorch.float).random_(5).to(device)\n    loss \u003d loss_fn(output, label)\n    loss.backward()\n    opt.step()\n    print(i)\n    ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "\n##根据迭代次数调整学习率\n\n\n当我们知道了optimizer的设置和分组之后，其实我们只需要在其\u0027params_group\u0027下的每一个组进行学习率即\u0027lr\u0027的关键值\n修改即可\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "\ndef adjust_learning_rate(optimizer, epoch, lr):\n    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 2 epochs\"\"\"\n    lr *\u003d (0.1 ** (epoch // 2))\n    for param_group in optimizer.param_groups:\n        param_group[\u0027lr\u0027] \u003d lr\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% \n",
          "is_executing": false
        }
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "0 1.0000000000000007e-15\n1 1.0000000000000007e-15\n2 1.0000000000000007e-16\n3 1.0000000000000007e-16\n4 1.0000000000000008e-17\n5 1.0000000000000008e-17\n6 1.0000000000000008e-18\n7 1.0000000000000008e-18\n8 1.0000000000000008e-19\n9 1.0000000000000008e-19\n"
          ],
          "output_type": "stream"
        },
        {
          "data": {
            "text/plain": "[\u003cmatplotlib.lines.Line2D at 0x1dc8e70a828\u003e]"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 14
        },
        {
          "data": {
            "text/plain": "\u003cFigure size 432x288 with 1 Axes\u003e",
            "image/png": "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\u003d\u003d\n"
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": "%matplotlib inline\nimport matplotlib.pyplot as plt\nlr0_init \u003d opt2.param_groups[0][\u0027lr\u0027]\ny \u003d []\nfor epoch in range(10):\n    adjust_learning_rate(opt2, epoch, lr0_init)\n    lr \u003d opt2.param_groups[0][\u0027lr\u0027]\n    print(epoch, lr)\n    y.append(lr)\n\nplt.plot(list(range(10)),y)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%  \n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}